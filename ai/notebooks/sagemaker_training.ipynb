{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb72c58",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Training Job\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Preparing training data\n",
    "- Uploading data to S3\n",
    "- Launching a SageMaker training job in script mode\n",
    "- Deploying a model endpoint\n",
    "- Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053566ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/sklearn-rf-demo\"\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"S3 Bucket: {bucket}\")\n",
    "print(f\"Prefix: {prefix}\")\n",
    "\n",
    "# Get execution role (or use a specific role ARN)\n",
    "try:\n",
    "    role = get_execution_role()\n",
    "except:\n",
    "    role = \"arn:aws:iam::YOUR-ACCOUNT-ID:role/SageMakerExecutionRole\"\n",
    "    print(f\"Note: Update role ARN if running locally: {role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780bebf2",
   "metadata": {},
   "source": [
    "## 1. Prepare Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f707b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic classification data\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create DataFrames (last column is target)\n",
    "train_df = pd.DataFrame(\n",
    "    np.column_stack([X_train, y_train])\n",
    ")\n",
    "test_df = pd.DataFrame(\n",
    "    np.column_stack([X_test, y_test])\n",
    ")\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# Save locally\n",
    "train_df.to_csv(\"train.csv\", index=False, header=False)\n",
    "test_df.to_csv(\"test.csv\", index=False, header=False)\n",
    "\n",
    "print(\"✓ Data saved locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b37c9",
   "metadata": {},
   "source": [
    "## 2. Upload Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ddafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to S3\n",
    "train_input = sagemaker_session.upload_data(\n",
    "    path=\"train.csv\",\n",
    "    bucket=bucket,\n",
    "    key_prefix=f\"{prefix}/data/train\"\n",
    ")\n",
    "\n",
    "test_input = sagemaker_session.upload_data(\n",
    "    path=\"test.csv\",\n",
    "    bucket=bucket,\n",
    "    key_prefix=f\"{prefix}/data/test\"\n",
    ")\n",
    "\n",
    "print(f\"Train data uploaded to: {train_input}\")\n",
    "print(f\"Test data uploaded to: {test_input}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb151919",
   "metadata": {},
   "source": [
    "## 3. Launch SageMaker Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0813aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SKLearn estimator\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"../src/sagemaker/train_script.py\",\n",
    "    role=role,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    framework_version=\"1.2-1\",\n",
    "    py_version=\"py3\",\n",
    "    hyperparameters={\n",
    "        \"n-estimators\": 100,\n",
    "        \"max-depth\": 10,\n",
    "        \"random-state\": 42\n",
    "    },\n",
    "    output_path=f\"s3://{bucket}/{prefix}/output\",\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "print(\"Estimator created. Starting training job...\")\n",
    "print(\"Note: This will take 5-10 minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d217bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "sklearn_estimator.fit({\n",
    "    \"train\": train_input,\n",
    "    \"test\": test_input\n",
    "})\n",
    "\n",
    "print(\"✓ Training complete!\")\n",
    "print(f\"Model artifacts: {sklearn_estimator.model_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b4acdd",
   "metadata": {},
   "source": [
    "## 4. Deploy Model to Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615f9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy model (this takes 5-10 minutes)\n",
    "predictor = sklearn_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\",\n",
    "    endpoint_name=\"sklearn-rf-endpoint\"\n",
    ")\n",
    "\n",
    "print(\"✓ Endpoint deployed!\")\n",
    "print(f\"Endpoint name: {predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cec8c2",
   "metadata": {},
   "source": [
    "## 5. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d52a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction with a sample\n",
    "sample = X_test[0:1]\n",
    "prediction = predictor.predict(sample)\n",
    "\n",
    "print(f\"Sample features: {sample[0][:5]}... (showing first 5)\")\n",
    "print(f\"Prediction: {prediction}\")\n",
    "print(f\"Actual: {y_test[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec13807b",
   "metadata": {},
   "source": [
    "## 6. Clean Up Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06af55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete endpoint to avoid charges\n",
    "# Uncomment to delete:\n",
    "# predictor.delete_endpoint()\n",
    "# print(\"✓ Endpoint deleted\")\n",
    "\n",
    "print(\"⚠️  Remember to delete the endpoint when done to avoid charges:\")\n",
    "print(f\"   predictor.delete_endpoint()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21984bde",
   "metadata": {},
   "source": [
    "## Cost Optimization Tips\n",
    "\n",
    "1. **Use Spot Instances** for training to save up to 70%\n",
    "2. **Delete endpoints** immediately after testing\n",
    "3. **Use Inference Recommender** to find optimal instance types\n",
    "4. **Enable autoscaling** for production endpoints\n",
    "5. **Use batch transform** instead of real-time endpoints when possible\n",
    "\n",
    "See `docs/06-sagemaker.md` for more details."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
